[
  {
    "objectID": "module4.html",
    "href": "module4.html",
    "title": "5  Module 4: Teaching with AI – Classroom Policies and Academic Integrity",
    "section": "",
    "text": "5.1 References\nslides\nAI tools like ChatGPT present both opportunities and challenges in the classroom. Educators are grappling with questions of if, when, and how students should (or shouldn’t) use AI in coursework. In this module, we examine emerging classroom policies regarding AI assistance, highlighting examples from the University of Michigan, Carnegie Mellon University (CMU), and University of Texas (UT). We also discuss how to communicate these policies to students to uphold academic integrity while embracing innovation.\n1. The Spectrum of AI Policies: Universities and instructors have staked out a range of positions:\nAt University of Michigan, guidance emphasizes four principles for GenAI use:\nThey outline three broad policy categories:\nUT Austin’s teaching center similarly notes that no new policy is needed – using uncredited AI is already cheating under existing rules – but urges faculty to decide and declare their stance clearly UT Center for Teaching and Learning.\n2. Rationale and Challenges: Why might an instructor choose a strict vs. lenient policy?\n3. Example Policies from Michigan, CMU, UT:\n4. Hands-On Exercise 4: Drafting an AI Policy. Now, participants will craft a short AI policy for a hypothetical course they teach, using the examples as inspiration:\n5. Final Thoughts on Policies: Crafting AI policies is now a key part of syllabus design. The best policies align with learning goals and are communicated clearly to students. As Michigan’s guidance notes, transparency and flexibility are crucial (University of Michigan Generative Artificial Intelligence: Course Policies & Syllabi Statements). By setting the ground rules, we can allow students to benefit from AI’s assistance while maintaining integrity and ensuring they still learn the material. In Module 5, we will look beyond the classroom to how faculty themselves can continue to grow with AI and adapt curricula.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Module 4: Teaching with AI – Classroom Policies and Academic Integrity</span>"
    ]
  },
  {
    "objectID": "module4.html#references",
    "href": "module4.html#references",
    "title": "5  Module 4: Teaching with AI – Classroom Policies and Academic Integrity",
    "section": "",
    "text": "University of Michigan (Center for Academic Innovation). 2023. “Generative AI Guidance for Instructors.”\n– Offers principles (transparency, responsibility) and example syllabus statements for AI use .\nCarnegie Mellon University Eberly Center. 2023. “Examples of Academic Integrity Policies for AI Tools.”\n– Contains sample policies ranging from total ban to full integration, e.g., requiring prompt/response in appendix if AI used .\nUniversity of Texas at Austin, Center for Teaching and Learning. 2023. “ChatGPT and Generative AI: Sample Syllabus Policy Statements.”\n– Emphasizes that uncredited AI use falls under existing plagiarism rules and provides multiple wording options for different stances.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Module 4: Teaching with AI – Classroom Policies and Academic Integrity</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Teaching Data Science with AI",
    "section": "",
    "text": "Preface\nslides\nWorkshop Overview: Welcome to “Teaching Data Science with AI,” a one-day workshop for social and political science educators. This workshop introduces how generative artificial intelligence (GenAI) can be leveraged in data science teaching and research workflows. We will explore modern AI tools – from large language models (LLM) to AI-assisted data methods – and discuss best practices for integrating these tools into curriculum design and research.\n\nModules: Five modules cover topics from research applications of AI, data collection with AI (web scraping and APIs), AI-enhanced analysis and visualization, classroom policies on AI, to faculty AI literacy and curriculum design.\nHands-On Exercises: Each module includes coding exercises (primarily in R, with some Python) to practice using AI tools or techniques in data science tasks.\nAudience: This workshop is aimed at faculty, post-doctoral fellows, and advanced users in difference disciplines from social sciences, business to data sciecne. There is no prerequisite but participants will have some advantage with experience in data analysis and AI models (e.g. Copilot and ChatGPT).\n\n\n“In 20 years following the internet space, we cannot recall a faster ramp in a consumer app,” noted analysts when ChatGPT reached 100 million users just two months post-launch UPCEA. The rapid rise of AI tools like ChatGPT underscores their transformative potential in academia. In this workshop, we’ll learn not only what these tools can do, but how to use them effectively and ethically in teaching and research.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Teaching Data Science with AI</span>"
    ]
  },
  {
    "objectID": "ParallelProcessing.html",
    "href": "ParallelProcessing.html",
    "title": "Appendix B — Appendix B: Parallel Processing Techniques",
    "section": "",
    "text": "Some tasks in data science (and AI experiments) can benefit from parallel processing – using multiple CPU cores or machines to run computations simultaneously. While not a focus of our workshop, we include a brief overview for those interested in speeding up heavy workloads (such as scraping many pages or running many simulations).\nB1. Why Parallelize? If a job takes 10 hours on one core, in theory splitting it across 10 cores could finish it in ~1 hour. In practice, parallelization has overhead, but it’s invaluable for tasks like: - Web scraping a large number of pages (to stay polite, you might still throttle per site, but you can scrape multiple sites in parallel). - Running cross-validation or hyperparameter tuning for machine learning models. - Simulations or bootstrapping in statistics.\nB2. Parallel Tools in R:\n\nBase R includes the parallel package. For example, mclapply() on Linux/macOS can apply a function in parallel. On Windows, one can use parLapply() with a cluster.\nThe future package along with furrr (for parallel map with purrr syntax) provides a more user-friendly approach. For instance:\n\n\n\nCode\nlibrary(future)\nplan(multisession, workers = 4)  # use 4 cores\nlibrary(furrr)\nresults &lt;- future_map(1:100, ~ { Sys.sleep(1); .x^2 })",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Appendix B: Parallel Processing Techniques</span>"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Bridging AI Readiness Gaps: Evidence-Based Pedagogical Design\nslides\nArtificial Intelligence (AI) is rapidly becoming ubiquitous in research and education. The advent of accessible large language models (LLMs) like OpenAI’s ChatGPT has opened new possibilities for data science research and pedagogy. Social and political scientists are beginning to ask how these AI models can enhance (or disrupt) traditional research workflows and teaching designs. This introduction provides context for the workshop and previews the modules ahead.\nThe Digital Education Council’s 2025 Global AI Faculty Survey (n=1,681) reveals critical disconnects in AI integration readiness that directly inform data science education reform. With 61% of faculty already using AI for teaching materials creation but 88% doing so minimally, programs must move beyond basic tool adoption to strategic implementation. Three key findings demand curricular attention:\nSurvey Results\n\n\n\nMetric\nFaculty (2025)\nStudents (2024)\n\n\n\n\nRegular AI Users\n61%\n86%\n\n\nWeekly/Daily Users\n44%\n54%\n\n\nConcerned About Evaluation\n83%\n60%\n\n\nSatisfied with Support\n6%\n20%\n\n\n\n\n\n\n\n\nTable 1: Faculty vs Student Usage of AI Tools\nThis motivates this workshop in particular proposing a curricular response to the survey findings.\nThis calls for:",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#references",
    "href": "introduction.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\n\nCraig, Madeline. 2025. “Earning Our AI Literacy License.” Faculty Focus (February 12). – Emphasizes the need for faculty to become AI literate rather than banning AI weblink\nKovács, Balázs, Gaël Le Mens, Michael Hannan, and Guillem Pros. 2024. “Can ChatGPT Accelerate Social Science Research?” Yale Insights (Jan 31). – Case study where ChatGPT replicated a specialized model’s results in a fraction of the time weblink.\nReuters. 2023. “ChatGPT sets record for fastest-growing user base.” Reuters Technology News (Feb 2). – Report on ChatGPT reaching 100 million users in 2 months, fastest-ever adoption of a consumer app weblink.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "module1.html",
    "href": "module1.html",
    "title": "2  Module 1: AI in Research Workflows – Comparing Models and Tools",
    "section": "",
    "text": "slides\nHow do different AI models fit into our research workflows? In this module, we compare various AI approaches and tools, examining their roles in tasks like data analysis, text generation, and coding assistance. We’ll contrast traditional machine learning models (e.g., BERT-based classifiers) with generative AI (e.g., GPT-4) and discuss how each can be used by social scientists.\n1. AI Model Landscape: Modern AI for research largely revolves around foundation models – very large models trained on broad data.\nThese models are pre-trained on vast datasets and can be fine-tuned for specific tasks. They include:\n\nGenerative AI (e.g., GPT-4, Claude): These models generate text, images, or other content based on prompts. They are often used for creative tasks, such as writing, summarizing, or generating code.\nTransformers for Understanding (e.g., BERT, RoBERTa): These models are designed to understand and analyze text. They excel in tasks like sentiment analysis, named entity recognition, and other classification tasks.\nVision Models (e.g., CLIP, DALL-E): These models are trained on images and can generate or analyze visual content. They are used in tasks like image classification, object detection, and generating images from text prompts.\nReinforcement Learning Models (e.g., AlphaGo, OpenAI Five): These models learn to make decisions by interacting with an environment. They are used in tasks like game playing and robotics.\nMultimodal Models (e.g., GPT-4, CLIP): These models can process and generate content across multiple modalities (text, images, audio). They are used in tasks that require understanding and generating content in different formats.\nAudio Models (e.g., Whisper): These models are designed to process and generate audio content. They are used in tasks like speech recognition, text-to-speech synthesis, and music generation.\nReinforcement Learning from Human Feedback (RLHF): This approach combines reinforcement learning with human feedback to improve model performance. It is used in tasks where human judgment is crucial, such as dialogue systems and content generation.\nDiffusion Models (e.g., Stable Diffusion): These models generate images by iteratively refining random noise into coherent images. They are used in tasks like image synthesis and style transfer.\nGraph Neural Networks (GNNs): These models are designed to work with graph-structured data. They are used in tasks like social network analysis, recommendation systems, and molecular property prediction.\nNeural Architecture Search (NAS): This approach automates the design of neural networks, optimizing their architecture for specific tasks. It is used in tasks where model performance is critical, such as image classification and natural language processing.\nFederated Learning: This approach allows models to be trained across multiple devices without sharing raw data. It is used in tasks where data privacy is a concern, such as healthcare and finance.\nSelf-supervised Learning: This approach uses unlabeled data to pre-train models, allowing them to learn useful representations without extensive labeled datasets. It is used in tasks where labeled data is scarce, such as natural language processing and computer vision.\nTransfer Learning: This approach leverages knowledge from one domain to improve performance in another. It is used in tasks where data is limited, such as medical image analysis and low-resource languages.\nZero-shot and Few-shot Learning: These approaches allow models to generalize to new tasks with little or no training data. They are used in tasks where labeled data is scarce, such as natural language processing and computer vision.\nPrompt Engineering: This approach involves designing effective prompts to elicit desired responses from models. It is used in tasks where model behavior needs to be controlled, such as dialogue systems and content generation.\nExplainable AI (XAI): This approach focuses on making AI models interpretable and understandable. It is used in tasks where model transparency is crucial, such as healthcare and finance.\n\nFor language tasks, two dominant paradigms are Generative models (like GPT series) and Transformers for understanding (like BERT).\n\nGenerative models are trained to predict the next word in a sequence, allowing them to generate coherent text. They are often used for tasks like text generation, summarization, and translation.\nConversely, BERT and its variants are trained to understand the context of words in a sentence, making them suitable for tasks like sentiment analysis, named entity recognition, and question answering.\nFor example, BERT is trained to predict masked words in a sentence, allowing it to learn the relationships between words and their context. This makes BERT particularly effective for tasks that require understanding the meaning of text, such as sentiment analysis and named entity recognition.\nGenerative AI (e.g., GPT-4, Claude): These models generate text, images, or other content based on prompts. They are often used for creative tasks, such as writing, summarizing, or generating code.\nTransformers for Understanding (e.g., BERT, RoBERTa): These models are designed to understand and analyze text. They excel in tasks like sentiment analysis, named entity recognition, and other classification tasks.\n\nIn essence, “GPT’s strength lies in generating text, whereas BERT excels in tasks that require a deep understanding of language context” Geeks for Geeks: Differences Between GPT and BERT. Generative models (GPT-3.5, GPT-4, etc.) can produce fluent text or code, making them ideal for drafting reports, summarizing articles, or writing code snippets. BERT-like models, on the other hand, are better at classification or extracting information (e.g., sentiment analysis, named-entity recognition) since they encode meaning bidirectionally rather than generate new text Geeks for Geeks: Differences Between GPT and BERT Geeks for Geeks: Differences Between GPT and BERT.\n2. Research Workflow Integration: Consider a typical research workflow in political science:\n\nLiterature Review – AI tools like Elicit or Bing Chat can summarize papers or suggest relevant literature.\nData Collection & Cleaning – We’ll see in Module 2 how AI can help fetch or parse data.\nAnalysis – AI can assist in coding (through code completion tools or generating analysis scripts) and even in choosing methods (e.g., suggesting whether to use a regression or a classification model for a given problem).\nWriting & Dissemination – Generative models can draft portions of manuscripts or create engaging summaries for presentations.\n\nThroughout these stages, choosing the right AI model is key. Simpler models or scripted rules might suffice for well-defined tasks (and be easier to interpret), whereas an LLM can be powerful for open-ended tasks like interpreting qualitative data. A notable example: Kovács et al. (2024) spent three years training a BERT-based model to measure a concept (“typicality”), only to find that ChatGPT could “duplicate their results at a fraction of the cost” in time and resources Kovács et al. (2024). This doesn’t mean BERT is obsolete – but it highlights how general-purpose GPT models can accelerate certain research tasks dramatically with minimal setup.\n3. Hands-On Exercise\n1: Comparing AI Tools on a Task. In this exercise, we will compare outputs from two AI systems on a common task:\n\nTask: Summarize a political news article in one paragraph.\n\nTool A: A pre-trained BERT-based summarizer (for instance, using an extractive summarization library).\nTool B: GPT-4 via an API call.\n\nProcedure: We provide both tools the same article text and examine the summaries produced. Below is pseudo-code in R to illustrate how one might invoke these:\n\n\n\nCode\n# Pseudo-code: comparing a BERT summarizer vs. GPT-3.5\narticle_text &lt;- \"Trump said they've agreed to open China, fully open China, and I think it's going to be fantastic for China, I think it's going to be fantastic for us, and I think it's going to be great for unification and peace, he said, without mentioning Taiwan.\"\n\n# Using a hypothetical BERT-based model via Python (reticulate or other package)\n## Recommended Python Interpreter: Anaconda\n## Conda Python 3.10.x\n## install.packages(\"reticulate\") # Install reticulate if not already installed\nlibrary(reticulate)\ntransformers &lt;- import(\"transformers\")\nsummarizer &lt;- transformers$pipeline(\"summarization\", model = \"facebook/bart-large-cnn\")\n\n# Generate summary\nbert_summary &lt;- summarizer(\n  article_text,\n  max_length = as.integer(50),\n  min_length = as.integer(15),\n  do_sample = FALSE\n)[[1]]$summary_text\n\ncat(bert_summary)\n\n\n# Using GPT-4.0 via ellmer and OpenAI API (assuming API key is set as environment variable)\n\n\nCode\nlibrary(openai)  # OpenAI API R wrapper\n### Set your OpenAI API key once\n## Sys.setenv(\n##    OPENAI_API_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n## )\n\n## install.packages(\"tidyverse/ellmer\") # Install ellmer if not already installed\nlibrary(ellmer)\n\n# Initialize the Chat object\ntwchat_obj &lt;- chat_openai(\n  model = \"gpt-4o\",\n  system_prompt = \"You are a Taiwan expert.\"\n)\n\ntwchat_obj$chat(paste0(\"Summarize this article in one sentence:\", \"\\n\", article_text))\nresponse &lt;- twchat_obj$last_turn(role = \"assistant\")\n# Print and compare summaries\ncat(\"BERT-based Summary:\\n\", bert_summary, \"\\n\\nGPT-4 Summary:\\n\", response@text)\n\n\n\n3 References\nAlayrac, Jean-Baptiste, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, et al. 2022. “Flamingo: A Visual Language Model for Few-Shot Learning.” Advances in Neural Information Processing Systems 35: 23716-23736.\nAnthropic. 2023. “Claude: A Next-Generation AI Assistant Based on Constitutional AI.” https://www.anthropic.com/claude (May 15, 2025).\nArrieta, Alejandro Barredo, Natalia Díaz-Rodríguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador García, et al. 2020. “Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI.” Information Fusion 58: 82-115.\nBerner, Christopher, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław Dębiak, Christy Dennison, David Farhi, et al. 2019. “Dota 2 with Large Scale Deep Reinforcement Learning.” arXiv preprint arXiv:1912.06680.\nBommasani, Rishi, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, et al. 2021. “On the Opportunities and Risks of Foundation Models.” arXiv preprint arXiv:2108.07258.\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D. Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” Advances in Neural Information Processing Systems 33: 1877-1901.\nChen, Ting, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. “A Simple Framework for Contrastive Learning of Visual Representations.” In Proceedings of the 37th International Conference on Machine Learning, 1597-1607.\nChristiano, Paul F., Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. 2017. “Deep Reinforcement Learning from Human Preferences.” Advances in Neural Information Processing Systems 30: 4299-4307.\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” arXiv preprint arXiv:1810.04805.\nDhariwal, Prafulla, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, and Ilya Sutskever. 2020. “Jukebox: A Generative Model for Music.” arXiv preprint arXiv:2005.00341.\nElsken, Thomas, Jan Hendrik Metzen, and Frank Hutter. 2019. “Neural Architecture Search: A Survey.” Journal of Machine Learning Research 20(55): 1-21.\nHo, Jonathan, Ajay Jain, and Pieter Abbeel. 2020. “Denoising Diffusion Probabilistic Models.” Advances in Neural Information Processing Systems 33: 6840-6851.\nLiu, Pengfei, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023. “Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing.” ACM Computing Surveys 55(9): 1-35.\nLiu, Yinhan, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. “RoBERTa: A Robustly Optimized BERT Pretraining Approach.” arXiv preprint arXiv:1907.11692.\nMcMahan, Brendan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. 2017. “Communication-Efficient Learning of Deep Networks from Decentralized Data.” In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, 1273-1282.\nOpenAI. 2023. “GPT-4 Technical Report.” arXiv preprint arXiv:2303.08774.\nPan, Sinno Jialin, and Qiang Yang. 2009. “A Survey on Transfer Learning.” IEEE Transactions on Knowledge and Data Engineering 22(10): 1345-1359.\nRadford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, et al. 2021. “Learning Transferable Visual Models from Natural Language Supervision.” In Proceedings of the 38th International Conference on Machine Learning, 8748-8763.\nRadford, Alec, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2023. “Robust Speech Recognition via Large-Scale Weak Supervision.” arXiv preprint arXiv:2212.04356.\nRamesh, Aditya, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022. “Hierarchical Text-Conditional Image Generation with CLIP Latents.” arXiv preprint arXiv:2204.06125.\nReynolds, Laria, and Kyle McDonell. 2021. “Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm.” In CHI Conference on Human Factors in Computing Systems Extended Abstracts, 1-7.\nRombach, Robin, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2022. “High-Resolution Image Synthesis with Latent Diffusion Models.” In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 10684-10695.\nSilver, David, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, et al. 2016. “Mastering the Game of Go with Deep Neural Networks and Tree Search.” Nature 529(7587): 484-489.\nZhou, Jie, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. 2020. “Graph Neural Networks: A Review of Methods and Applications.” AI Open 1: 57-81.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Module 1: AI in Research Workflows – Comparing Models and Tools</span>"
    ]
  },
  {
    "objectID": "module5.html",
    "href": "module5.html",
    "title": "6  Module 5: Faculty AI Literacy and Curriculum Redesign",
    "section": "",
    "text": "6.1 1. Why Faculty AI Literacy?\nslides\nThe final module turns the focus onto us, the educators and researchers. How do we stay ahead of the curve with AI, and how might we redesign curricula to prepare students for an AI-infused world? We discuss strategies for improving faculty AI literacy and brainstorm ways to incorporate AI into teaching plans in a pedagogically sound manner.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Module 5: Faculty AI Literacy and Curriculum Redesign</span>"
    ]
  },
  {
    "objectID": "module5.html#references",
    "href": "module5.html#references",
    "title": "6  Module 5: Faculty AI Literacy and Curriculum Redesign",
    "section": "6.7 References",
    "text": "6.7 References\n\nCraig, Madeline. 2025. “Earning Our AI Literacy License.” Faculty Focus\n– Argues that banning AI is futile and faculty should become AI literate alongside students\nU.S. Department of Education. 2023. “Guidance on AI in Education.”\n– (Referenced in Craig 2025) Highlights the national push for AI literacy in curricula.\nGenerative AI for Educators. 2023. Google\n– A free online course for teachers to learn how to use AI in teaching.\nElements of AI. 2018. University of Helsinki\n– Free online AI fundamentals course, popular for broad audiences.\nEDUCAUSE. 2023. “AI Literacy in Teaching and Learning”.”\n– Describes a faculty development program to integrate AI into course design.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Module 5: Faculty AI Literacy and Curriculum Redesign</span>"
    ]
  },
  {
    "objectID": "gc.html",
    "href": "gc.html",
    "title": "Appendix A — Appendix A: Generative Computing & Efficiency Tips",
    "section": "",
    "text": "This technical appendix provides additional notes on generative computing (using generative AI in coding) and some efficiency tips (like memory management) that supplement our workshop content.\n\nA.0.1 A1. Generative AI in Coding (Additional Examples):\nIn Module 1 and Module 3, we saw how AI can generate code or assist in coding tasks. Here are a few more pointers:\n\nCode Completion Tools:\n\nApart from ChatGPT, tools like GitHub Copilot (powered by OpenAI Codex) can be integrated into IDEs. They work by predicting your next lines of code. Many faculty have found Copilot helpful for writing repetitive code or exploring unfamiliar libraries, effectively acting as a “pair programmer” with auto-completion.\nWith education ID, apply in GitHub. It takes same day to approve.\n\nPrompt Engineering for Coding:\n\nWhen using generative AI for coding, how you ask matters. For example, “Write an R function to calculate the Gini coefficient from a numeric vector” will yield a more targeted result than “Give me code for Gini”. Be specific about language (R/Python), input/output, and even style.\n\nVerification: Always test and verify AI-generated code. Treat it like code from a student – likely correct on straightforward tasks, but possibly flawed on complex ones. AI might use outdated functions or assume things. For instance, if ChatGPT suggests using spread() from tidyr (which is deprecated in favor of pivot_wider()), you’ll need to catch that.\n\n\n\nA.0.2 A2. Memory Management and Garbage Collection (for R users):\n\nWhen working with large data or running many AI model calls, you might encounter performance issues. R has a garbage collector (gc() function) that frees up memory. While our one-day workshop exercises are small-scale, if you continue experimenting with AI (say calling an API thousands of times, or fine-tuning models), remember:\n\nUse gc() to explicitly prompt R to clear unused memory if you notice memory bloat.\n\nMonitor memory usage with tools like pryr or base R’s memory.size() (on Windows).\nPython users: similarly, be aware of memory when loading big models (use del and gc.collect() from the gc module if needed).\nSee also Data Programming with GenAI Appendix II\n\n\n\nA.0.3 A3. Dealing with Rate Limits (API efficiency):\n\nIf writing a script to collect data via an API or to use an AI service repeatedly, you might hit rate limits:\n\nCheck if the API allows batch requests. For example, the OpenAI API lets you send multiple prompts in one request (as an array) in some endpoints.\nIntroduce pauses between requests using Sys.sleep() in R or time.sleep() in Python to avoid triggering caps.\nIf doing a large scraping job, consider parallel processing (see Appendix B) to speed up while still being polite (distributing load, not exceeding per-IP limits).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Appendix A: Generative Computing & Efficiency Tips</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "7  Conclusion",
    "section": "",
    "text": "Over the course of this workshop, we have journeyed through the landscape of “Teaching Data Science with AI.” From understanding AI models and integrating them into research workflows, to practical data collection techniques, through analysis enhancements, and finally grappling with the pedagogical and ethical implications, it’s clear that AI is set to play a significant role in academia.\nKey Takeaways:\n\nAI as Accelerator, Not Replacement: One recurring theme was that AI can amplify our capabilities – helping us work faster or see patterns – but it doesn’t replace the need for human judgment. Whether it was checking a GPT summary against the source, or interpreting a complex model’s output, the human researcher/teacher remains in the loop.\nBalance of Innovation and Integrity: We explored how to welcome AI tools in the classroom and research while maintaining rigor and honesty. Clear policies and attribution practices (citing AI like any other source) are part of this balance.\nContinuous Learning: The AI field evolves rapidly. Faculty and students alike must adopt a mindset of lifelong learning. What we learned about GPT-4 today might apply to GPT-5 or a completely new tool tomorrow. The specific tools matter less than the adaptable skills – critical thinking, ethical reasoning, and the ability to learn new technologies.\n\nLooking Forward: In the near future, we might see AI more deeply integrated into research software (imagine your data analysis IDE autocompleting not just code, but suggesting which analysis to run). In education, AI tutors could personalize learning for students, while instructors become orchestrators of human-AI collaboration in the classroom. These prospects are exciting, but they also require us to be vigilant about issues like bias, equity, and the preservation of fundamental skills.\nWe encourage you to take the materials from this workshop – the book chapters, code examples, slide decks, and your own notes – and apply them in your context. Try out that web scraping exercise on a dataset from your research. Modify your syllabus to include an AI-use statement. Share what you learned with colleagues in your department. By doing so, you contribute to a community of practice that is figuring out how to harness AI for the advancement of social science.\nThank you for your active participation and curiosity. As a final light-hearted sendoff: May your code be bug-free, your AI be hallucination-free, and your next grant proposal be co-written by ChatGPT (and get funded)!\nHappy teaching and researching with AI!",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "module2.html",
    "href": "module2.html",
    "title": "3  Module 2: AI-Assisted Data Collection",
    "section": "",
    "text": "3.1 Overview\nslides\nThis module focuses on data collection using API and other methods. It introduces web scraping with rvest and Python requests Real Python, including code examples.\nEthics of scraping are mentioned with a light Spider-Man reminder. It covers using APIs vs scraping. The exercise involves scraping a Wikipedia table with R and then using an AI (GPT) to summarize the scraped data. This demonstrates AI’s added value in interpretation. References include rvest docs and a Python requests guide.)*\nIn the digital age, vast amounts of data are available online. Collecting and utilizing this data effectively is crucial for data science and AI applications. This module focuses on:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Module 2: AI-Assisted Data Collection</span>"
    ]
  },
  {
    "objectID": "module3.html",
    "href": "module3.html",
    "title": "4  Module 3: AI for Analysis & Visualization – From Regression to Machine Learning",
    "section": "",
    "text": "slides\nIn this module, we examine how AI can support data analysis and visualization. We’ll demonstrate how GPT (or similar AI) can assist in creating visuals and insights, and then dive into a comparison between a traditional statistical approach (linear regression) and a machine learning approach on a research problem. The goal is to illustrate benefits and limitations of each, helping us decide when to use which in our own research.\n1. GPT-Enhanced Data Visualization: Imagine having a data visualization assistant who can generate charts on the fly from your data. Recent integrations (like GPT-4’s code interpreter or tools in BI software) do just that – you describe what you want, and the AI produces a chart. “ChatGPT excels at generating a range of well-understood exploratory charts… in only a few seconds”, allowing rapid iteration in the early data exploration stage (van Dijk 2024). For example, you could prompt an AI: “Here is my dataset of survey responses, please plot a bar chart of age distribution.” The AI might return a code (and even an image) of the requested chart. This lowers the barrier for non-programmers to create visuals and lets analysts quickly try many ideas. However, AI-generated visuals still require human oversight: the AI might pick an inappropriate chart type or scale, and complex customizations (titles, annotations) often need manual refinement (van Dijk 2024: Data exploration).\nVisual Example: Below is a comparison of a simple linear model vs. a machine learning model fit (details in section 2). The blue line is a linear regression’s fit to data, while the red line is a more flexible model’s fit (random forest).\n\nExample: A linear regression (blue) versus a random forest model (red) fitting a nonlinear dataset. The machine learning model captures complex patterns that the straight-line regression misses, but at the cost of interpretability.\n\nRegression vs. Machine Learning – A Comparative Demo: Social scientists often default to regression models (like OLS) for their analysis, valuing the clear interpretation of coefficients. Machine learning models (like random forests, neural nets) can model complex relationships but are sometimes seen as “black boxes.” Leo Breiman’s famous essay described this as the “two cultures” of modeling: one focused on inference, the other on prediction. Let’s demonstrate the difference:\n\n\nScenario: We have data on some phenomenon (say, an index of political stability as a function of several indicators). We’ll fit a linear regression and a random forest regression to the data.\n\n\n\nCode\n# Simulate a nonlinear dataset\nset.seed(23)\nN &lt;- 100\nx1 &lt;- runif(N, 0, 10)\ny &lt;- sin(x1) + rnorm(N, 0, 0.3)\ndata &lt;- data.frame(x1, y)\n# Linear model\nlin_mod &lt;- lm(y ~ x1, data=data)\n# Random forest model\nlibrary(randomForest)\nrf_mod &lt;- randomForest(y ~ x1, data=data, ntree=100)\n# Predictions for plotting\nnewx &lt;- data.frame(x1 = seq(0, 10, 0.1))\nlin_pred &lt;- predict(lin_mod, newx)\nrf_pred &lt;- predict(rf_mod, newx)\nlinear= lm(y ~ x1, data=data)\nsummary(linear)\n\n\n\nCall:\nlm(formula = y ~ x1, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.52878 -0.53151  0.07751  0.63452  1.37925 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  0.322407   0.154712   2.084   0.0398 *\nx1          -0.008447   0.025375  -0.333   0.7399  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7422 on 98 degrees of freedom\nMultiple R-squared:  0.001129,  Adjusted R-squared:  -0.009063 \nF-statistic: 0.1108 on 1 and 98 DF,  p-value: 0.7399\n\n\nWe would then plot these as shown in the figure above.\n\n\nCode\n#| echo: true\n#| message: false\n#| warning: false\n#| include: true\n\n# Plot the actual data points\npar(family=\"Palatino\")\nplot(data$x1, data$y, pch = 20, col = \"gray40\",\n     main = \"Linear vs Random Forest Regression\",\n     xlab = \"x1\", ylab = \"y\", cex=.8)\n\n# Add the linear model predictions\nlines(newx$x1, lin_pred, col = \"steelblue\", lwd = 1.5)\n\n# Add the random forest predictions\nlines(newx$x1, rf_pred, col = \"forestgreen\", lwd = 1.5)\n\n# Add a legend\nlegend(\"top\", legend = c(\"Linear Model\", \"Random Forest\"),\n       col = c(\"steelblue\", \"forestgreen\"), lwd = 1.5)\n\n\n\n\n\n\n\n\n\n\n\nCode\n#| echo: true\n#| message: false\n#| warning: false\n#| include: true\n\n# Load ggplot2\nlibrary(ggplot2)\n\n\n\nAttaching package: 'ggplot2'\n\n\nThe following object is masked from 'package:randomForest':\n\n    margin\n\n\nCode\n# Create a data frame with predictions\nplot_df &lt;- data.frame(\n  x1 = newx$x1,\n  Linear = lin_pred,\n  RandomForest = rf_pred\n)\n\n# Convert to long format for ggplot2\nlibrary(tidyr)\nplot_df_long &lt;- pivot_longer(plot_df, cols = c(\"Linear\", \"RandomForest\"),\n                             names_to = \"Model\", values_to = \"Prediction\")\n\n# Generate the plot\nggplot(data, aes(x = x1, y = y)) +\n  geom_point(color = \"gray40\", size = .8) +\n  geom_line(data = plot_df_long, aes(x = x1, y = Prediction, color = Model), linewidth = .8) +\n  labs(title = \"Linear vs Random Forest Regression\",\n       x = \"x1\", y = \"y\") +\n  theme_bw() +\n  scale_color_manual(values = c(\"Linear\" = \"steelblue\", \"RandomForest\" = \"forestgreen\")) +\n  theme(legend.position = \"top\", text = element_text(family= \"Palatino\")) \n\n\n\n\n\n\n\n\n\nThe linear model gives a straight-line fit (easy to explain: “y decreases slightly with x1”), but clearly misses the sine-wave pattern in the data. The random forest captures the pattern (green curve) much better\n– if our goal was prediction, the ML model wins. - But the random forest doesn’t provide a simple equation or coefficient - it’s harder to interpret why it predicts the values it does at each point (the black box).\n\nDiscussion:\n\nIn research, the choice depends on the goal.\nIf we need to explain a relationship or test a hypothesis (“does x1 have a negative effect on y?”), a regression with its coefficient and p-value is useful.\nIf we need to predict accurately (say, forecasting an outcome or imputing missing data) and the relationship is complex, ML may perform better. Notably, hybrid approaches are emerging:\n\nidentify the most important variables\nuse them in a regression model\nuse the ML model to predict the residuals\nidentify anaomalies\n\n\n– Use AI to suggest additional features or transformations to improve a regression, or using simpler post-hoc explanation tools for ML models (like SHAP values).\n\n\nAI in Analysis: Beyond generating code for plots, AI can assist in analysis by:\n\n\nSuggesting which variables to include or potential interactions (based on literature it has seen).\nChecking assumptions (you could ask, “I fit a regression and got residuals like X, what might be wrong?”).\nWriting out interpretation of results (turning regression output into a narrative paragraph).\nHowever, caution: AI might not understand context or the theory behind your analysis – its suggestions should not override domain expertise. Think of it as an eager but inexperienced research assistant.\n\n\nHands-On Exercise 3: Exploring Regression vs ML with AI Hints. Using a provided dataset (we’ll supply a small dataset in class, e.g., a synthetic one with a nonlinear pattern like above):\n\n\nFit a linear model and a random forest model (or another ML model such as a boosted tree) to the data.\nCompare their performance (e.g., residual sum of squares or an R² on a test set).\nNow, try using an AI assistant to interpret the models. For instance, if using R, you might use an R plugin that connects to GPT, or simply copy your model summary into ChatGPT and ask “Explain these results.” See how the AI’s interpretation compares to yours.\nFor example, after fitting models to our data, we ask ChatGPT: “The linear model’s R² = 0.2, the random forest’s R² = 0.8 on test data. What does this imply?” The AI might respond with an explanation that the relationship is nonlinear and the flexible model captured it better, whereas the linear model left much variance unexplained – essentially articulating what we see in the plot.\n\nDiscuss: Did the AI correctly identify the key insight? How might you phrase the findings in an academic paper?\n\nConclusion: AI can accelerate and enhance the analysis phase – from creating visuals to interpreting results – but it doesn’t replace the need for us to understand our models. As one study noted, “human expertise remains crucial as you delve deeper” into analysis and visualization. The partnership of human and AI can lead to both efficient and insightful research, combining computational power with domain knowledge.\n\n\n4.0.1 References:\n\nvan Dijk, Dieuwertje. 2024. “ChatGPT as a collaborative tool for data visualization.”\n– Found that ChatGPT can quickly generate exploratory charts (bar, line, heatmap) for data, expediting initial analysis (Datylon Blog)..\nBreiman, Leo. 2001. “Statistical Modeling: The Two Cultures.” Statistical Science 16(3): 199–215.\n– Classic discussion on the divergence between inference-focused modeling vs. prediction-focused modeling in data analysis.\nStack Exchange (Cross Validated). 2014. Discussion on statistics vs ML.\n– Emphasizes the focus on inference in statistics vs prediction in ML",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Module 3: AI for Analysis & Visualization – From Regression to Machine Learning</span>"
    ]
  },
  {
    "objectID": "introduction.html#bridging-ai-readiness-gaps-evidence-based-pedagogical-design",
    "href": "introduction.html#bridging-ai-readiness-gaps-evidence-based-pedagogical-design",
    "title": "Introduction",
    "section": "",
    "text": "Evaluation Crisis:\nEighty-three percent (83%) of faculty express concern about students’ ability to critically assess AI outputs, while 82% fear over-reliance (see Table 2.1). This necessitates building AI literacy scaffolds into existing data science curricula through AI integration.\n\n\n\n\nModule 1 Integration:\nEmbed AI output evaluation frameworks within research methods training. For example, comparative analysis exercises where students assess ChatGPT vs. Claude outputs on the same dataset.\nModule 3 Enhancement:\nDevelop visualization assignments requiring students to detect AI-generated data anomalies through tools like GPT-powered Quarto dashboards.\n\n\nAssessment Obsolescence:\nFifty four percent (54%) of faculty demand assessment redesign, aligning with students’ 52% concern about AI devaluing education (Hoffman 2025).\n\n\n\nModule 4 Implementation:\nCreate AI-resistant assessments through:\nProcess-oriented evaluations: Scaffolded project logs tracking human-AI collaboration\nOral defenses: Requiring students to explain AI-generated code/outputs\nReal-world datasets: Using messy, unstructured data that challenges AI tools\n\n\nInstitutional Support Vacuum:\nWith 80% of faculty finding institutional guidelines inadequate and only 6% satisfied with AI resources, programs must build self-sufficient ecosystems:\n\nModule 5 Expansion:\nDevelop faculty learning communities (FLCs) using the survey’s regional disparity findings (78% LATAM faculty vs. 57% North American faculty view AI as opportunity) to create culturally responsive AI policies.\n\n\n\n\nData-Driven Curriculum Overhaul Framework\n\n\n\n\n\n\n\n\nSurvey Finding\nCurricular Response\nWorkshop Module Alignment\n\n\n\n\n61% faculty use AI for materials creation\nDevelop AI-assisted curriculum design labs\nModule 1: Case studies on AI-driven tool integration\n\n\n86% faculty anticipate future AI use\nCreate 3-year AI adoption roadmaps\nModule 5: Faculty dialogue on phased implementation\n\n\n66% see AI as essential for workforce prep\nPartner with industry to co-design capstone projects\nModule 2: Ethical data collection practicums\n\n\n\n\n\n\nTransforming Data Science Pedagogy: Four Imperatives\n\nFrom Tool Training to Critical Engagement\nWhile 75% of faculty use AI for materials creation, only 24% employ it for student feedback. Programs should:\n\nImplement AI critique modules where students audit algorithm biases in public datasets\nDevelop hygraded assignments combining AI-generated base content with human refinement\n\nEthical Infrastructure Development\nAddressing 61% student privacy concerns requires:\n\nModule 2 Enhancement:\nSimulated IRB exercises for AI-assisted data collection\nModule 4 Integration:\nGDPR/HIPAA compliance training specific to generative AI outputs\n\nCognitive Partnership Models\nWith 44% faculty using AI weekly vs. 54% students, design human-AI collaborative workflows:\n\nPrompt engineering studios: Using Claude for literature reviews vs. ChatGPT for code generation\nAI pair programming: Copilot-driven code development with human error checking\n\nAssessment Renaissance\nLeverage the 86% faculty openness to future AI use[12] through:\n\nAuthentic portfolio assessments: Showcasing iterative human-AI project development\nDynamic rubrics: Weighting AI-appropriate vs. human-exclusive competencies\n\n\n\n\n\nImplementation Roadmap for Program Directors\n\nDiagnostic Phase (Month 1-3)\n\nAdminister DEC’s AI Literacy Inventory to baseline faculty/student capabilities\nAudit existing courses using the AI Curriculum Integration Matrix\n\nPrototyping Phase (Month 4-6)\n\nPilot AI-enhanced modules in 20% of data science courses\nEstablish faculty AI sandbox with curated tools (ChatGPT, Copilot, Claude)\n\nScaling Phase (Month 7-12)\n\nImplement institution-wide AI ethics certification\nLaunch AI teaching assistant program using survey-driven competency gaps\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Faculty AI Usage and Perceptions\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: AI Adoption Comparison: Faculty vs Students\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Faculty vs Student Perspectives on Institutional Priorities\n\n\n\n\n\nAI in Data Science and Education: Generative AI’s ability to produce human-like text, code, and visuals on demand represents a paradigm shift. Tasks that once took hours (e.g., writing code or summarizing literature) can now be accelerated with AI assistance (Kovács et al 2024). At the same time, using AI in academia raises questions about reliability, ethics, and skills – issues we will revisit throughout the workshop. Banning AI outright is not a sustainable solution; “banning AI use in college classrooms is a pointless and exhausting endeavor” – instead, we should learn to use it responsibly alongside students (Craig 2025). Craig also introduces the concept of an AI literacy license for faculty, which we will discuss in Module 5. In his article, he suggests a list of online courses that faculty should take to earn this license, including Generative AI for Educators (from Google) and Empower Educators to Explore the Potential of Artificial Intelligence: (from Microsoft) This workshop aims to provide a practical introduction to these topics, equipping participants with the skills and knowledge to navigate the evolving landscape of AI in academia.\nWorkshop Goals: By the end of this workshop, participants will be able to:\n\nUnderstand the landscape of AI tools (especially LLMs) and their roles in social science research workflows.\nApply AI assistance in data collection (e.g., web scraping, API access) to gather research data more efficiently.\nIntegrate AI into data analysis and visualization processes (e.g. vibe coding), and critically compare traditional statistical methods with machine learning approaches.\n\n\n\n\n\n\n\nVibe coding\n\n\n\n\n\nWhat is vibe coding?\nVibe coding uses natural language prompts to instruct AI tools to generate code and build apps. This approach allows developers to instruct AI models to write modules or component codes so the human developer can focus on the overall design. Yang at Zapier 2025\n\n\n\n\nFormulate classroom policies on student use of AI that uphold academic integrity and foster learning, informed by emerging policies at institutions like Michigan, CMU, and UT.\nDevelop strategies for improving their own AI literacy and redesigning curricula to prepare students for an AI-augmented future.\n\nStructure: The workshop is organized into five modules, each a mix of lecture, demonstration, and hands-on exercise:\n\nAI in Research Workflows: Comparing different AI models and tools, and where they fit in a typical research pipeline.\nAI-Assisted Data Collection: Using AI and automation for web scraping and API data retrieval.\nAI for Analysis & Visualization: Enhancing data visualization with GPT and examining a case of regression vs. machine learning.\nTeaching with AI – Policies and Ethics: Crafting classroom policies for AI usage, with examples from several universities.\nAI Literacy for Faculty: Building educators’ AI skills and rethinking curriculum design.\n\nEach module will conclude with a practical exercise. We encourage an open mind and active participation—ask questions and share experiences. Let’s explore how AI can amplify our work as researchers and educators, while also understanding its limitations.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "module2.html#learning-objectives",
    "href": "module2.html#learning-objectives",
    "title": "3  Module 2: AI-Assisted Data Collection",
    "section": "3.2 Learning Objectives",
    "text": "3.2 Learning Objectives\nBy the end of this module, learners will be able to:\n1.  Understand the differences between web scraping and API-based data collection.\n2.  Use R and the rvest package to scrape data from web pages.\n3.  Identify and adhere to ethical guidelines in data collection.\n4.  Utilize AI tools to summarize and interpret collected data.\n\n3.2.1 Section 1: Web Scraping with R\nWhat is Web Scraping?\nWeb scraping involves programmatically extracting data from websites. It’s useful when data isn’t available through APIs or downloadable formats.\nTool: rvest Package in R\nThe rvest package simplifies web scraping by providing functions to:\n\nRead HTML content.\nNavigate and extract elements using CSS selectors.\nConvert extracted data into usable formats like data frames.\n\nExample: Scraping a Wikipedia Table\nLet’s scrape a table from Wikipedia, such as the list of countries by GDP.\n\n\nCode\n# Load necessary libraries\nlibrary(rvest)\nlibrary(dplyr)\n\n# Define the URL\nurl &lt;- \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n\n# Read the HTML content\npage &lt;- read_html(url)\n\n# Extract the first table on the page\ngdp_table &lt;- page %&gt;%\n  html_node(\"table.wikitable\") %&gt;%\n  janitor::clean_names() %&gt;%\n  html_table()\n\n# View the first few rows\nhead(gdp_table)\n\n\n# A tibble: 6 × 7\n  `Country/Territory` `IMF[1][12]` `IMF[1][12]` `World Bank[13]`\n  &lt;chr&gt;               &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;           \n1 Country/Territory   Forecast     Year         Estimate        \n2 World               113,795,678  2025         105,435,540     \n3 United States       30,507,217   2025         27,360,935      \n4 China               19,231,705   [n 1]2025    17,794,782      \n5 Germany             4,744,804    2025         4,456,081       \n6 India               4,187,017    2025         3,549,919       \n# ℹ 3 more variables: `World Bank[13]` &lt;chr&gt;, `United Nations[14]` &lt;chr&gt;,\n#   `United Nations[14]` &lt;chr&gt;\n\n\nExplanation:\n\nread_html() reads the HTML content of the page.\nhtml_node(“table.wikitable”) selects the first table with the class wikitable.\nhtml_table() converts the HTML table into a data frame.\n\nHowever, it returns bad data because of the first two rows. We can use some tricks to clean the names and remove the first two rows, thanks to ChatGPT.\n\n\nCode\n# Load necessary libraries\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(janitor)\nlibrary(stringr)\n\n# Define the URL\nurl &lt;- \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n\n# Read the HTML content\npage &lt;- read_html(url)\n\n# Extract all tables with the class 'wikitable'\ntables &lt;- page %&gt;% html_nodes(\"table.wikitable\")\n\n# Select the first table\ngdp_table &lt;- tables[[1]] %&gt;% html_table(header = FALSE)\n\n# Combine the first two rows to create column names\ncombined_headers &lt;- paste(gdp_table[1, ], gdp_table[2, ], sep = \" \")\ncombined_headers &lt;- str_remove_all(combined_headers, \"\\\\[.*?\\\\]\")\ncombined_headers &lt;- str_trim(combined_headers)\ncolnames(gdp_table) &lt;- combined_headers\n\n# Remove the first two rows from the data\ngdp_table &lt;- gdp_table[-c(1, 2), ]\n\n# Clean the column names\ngdp_table &lt;- gdp_table %&gt;% janitor::clean_names()\nnames(gdp_table)[names(gdp_table) == \"country_territory_country_territory\"] &lt;- \"country_territory\"\n\n# View the cleaned data\nhead(gdp_table)\n\n\n# A tibble: 6 × 7\n  country_territory imf_forecast imf_year  world_bank_estimate world_bank_year\n  &lt;chr&gt;             &lt;chr&gt;        &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;          \n1 World             113,795,678  2025      105,435,540         2023           \n2 United States     30,507,217   2025      27,360,935          2023           \n3 China             19,231,705   [n 1]2025 17,794,782          [n 3]2023      \n4 Germany           4,744,804    2025      4,456,081           2023           \n5 India             4,187,017    2025      3,549,919           2023           \n6 Japan             4,186,431    2025      4,212,945           2023           \n# ℹ 2 more variables: united_nations_estimate &lt;chr&gt;, united_nations_year &lt;chr&gt;\n\n\n\n\n3.2.2 Section 2: Ethical Considerations in Web Scraping\nBefore scraping data, it’s essential to consider:\n\nWebsite Terms of Service: Always check if the website permits data scraping.\nRobots.txt File: This file indicates which parts of the site can be crawled (e.g. https://www.govinfo.gov/robots.txt)\nRate Limiting: Avoid overwhelming servers by limiting the frequency of requests.\nData Privacy: Ensure that personal or sensitive information is handled appropriately.\n\n\n\nCode\nlibrary(rvest)\nlibrary(polite)\n\n# Ethical scraping session\nsession &lt;- bow(\"https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States\", \n               delay = 5, \n               user_agent = \"Academic Research Bot\")\n\n# Scrape using specific table selector\npresidents &lt;- scrape(session) %&gt;%\n  html_element(\"table.wikitable:nth-of-type(1)\") %&gt;%  # Targets first wikitable\n  html_table()\n\n# Check results\nif (length(presidents) == 0) {\n  stop(\"Table not found - check selector or page structure\")\n} else {\n  head(presidents)\n}\n\n\n# A tibble: 6 × 8\n  `No.[a]` Portrait `Name(birth–death)` `Term[16]` `Party[b][17]` `Party[b][17]`\n     &lt;int&gt; &lt;lgl&gt;    &lt;chr&gt;               &lt;chr&gt;      &lt;lgl&gt;          &lt;chr&gt;         \n1        1 NA       George Washington(… April 30,… NA             Unaffiliated  \n2        2 NA       John Adams(1735–18… March 4, … NA             Federalist    \n3        3 NA       Thomas Jefferson(1… March 4, … NA             Democratic-Re…\n4        4 NA       James Madison(1751… March 4, … NA             Democratic-Re…\n5        5 NA       James Monroe(1758–… March 4, … NA             Democratic-Re…\n6        6 NA       John Quincy Adams(… March 4, … NA             Democratic-Re…\n# ℹ 2 more variables: Election &lt;chr&gt;, `Vice President[18]` &lt;chr&gt;\n\n\nRemember: With great power comes great responsibility. Always scrape ethically!\n\n\n3.2.3 Section 3: Accessing Data via APIs\nAPIs provide structured access to data and are often the preferred method for data collection.\nAdvantages of APIs: - Structured and reliable data. - Legal and documented access. - Often more efficient than scraping.\nExample: Accessing Data from an API\nSuppose we have access to an API that provides GDP data. While the specific implementation depends on the API’s structure, the general approach in R would involve:\n\n\nCode\n# Load necessary library\nlibrary(httr)\n\n# Define the API endpoint\napi_url &lt;- \"https://api.example.com/gdp\"\n\n# Make a GET request\nresponse &lt;- GET(api_url)\n\n# Parse the content\ndata &lt;- content(response, \"parsed\")\n\n# Convert to a data frame\ngdp_data &lt;- as.data.frame(data)\n\n# View the data\nhead(gdp_data)\n\n\nNote: Replace https://api.example.com/gdp with the actual API endpoint.\n\n\n3.2.4 Section 4: AI-Powered Summarization\nAfter collecting data, AI models like GPT can help summarize and interpret the information.\nExample: Summarizing GDP Data\nAssuming we have a data frame gdp_table with GDP information, we can use an AI model to summarize the top countries by GDP.\n\n\nCode\n# Load necessary library\nlibrary(openai)\nlibrary(knitr)\nlibrary(ellmer)\n# Prepare the prompt\ntop_countries &lt;- gdp_table$country_territory[2:6]\ncountry_list &lt;- combine_words(top_countries)\nprompt_text &lt;- paste(\"Summarize the top 5 countries by GDP: \", country_list)\n\n# Initialize the Chat object\nchat_obj &lt;- chat_openai(\n  model = \"gpt-4o\",\n  system_prompt = \"You are a World economy expert.\"\n)\n\nchat_obj$chat(prompt_text)\n\n\nAs of the latest available data, the top five countries by GDP are the United \nStates, China, Japan, Germany, and India. Here's a brief overview of each:\n\n1. **United States**: The U.S. remains the world's largest economy, driven by a\ndiverse set of industries including technology, finance, healthcare, and \nconsumer goods. The country benefits from a large and affluent consumer base, \nstrong financial markets, and a robust innovation ecosystem. It also plays a \ncrucial role in global trade, with significant imports and exports.\n\n2. **China**: China ranks second in terms of GDP, underpinned by its status as \na global manufacturing hub and a rapidly growing consumer market. Its economy \nhas experienced rapid growth over the past few decades, though it faces \nchallenges such as managing debt levels, shifting towards a consumption-driven \neconomy, and addressing environmental concerns.\n\n3. **Japan**: Japan is the third largest economy and is known for its advanced \ntechnology, automotive industry, and electronics. It has a mature economy with \na high standard of living. Challenges include an aging population and \ndeflationary pressures that impact long-term growth prospects.\n\n4. **Germany**: As Europe's largest economy, Germany is renowned for its \nengineering, automotive, and manufacturing sectors. It is a major exporter and \nplays a key role in the European Union's economic structure. Germany's economic\nstability is often attributed to its industrial base, fiscal prudence, and \nsocial welfare systems.\n\n5. **India**: India rounds out the top five, driven by a large and youthful \npopulation, expanding services sector, and increasing integration into the \nglobal economy. It is a significant player in the IT services industry and has \na growing manufacturing base. India faces challenges such as infrastructure \ndevelopment, regulatory reforms, and socio-economic disparities.\n\nThese countries collectively represent a significant portion of the global \neconomy and influence global trade, investment flows, and economic policies.\n\n\nCode\nresponse &lt;- chat_obj$last_turn(role = \"assistant\")\n# Print and compare summaries\n\n# cat(response@text)\n\n# Generate the summary ready for corpus processing\nsummary &lt;- create_chat_completion(\n  model = \"gpt-4o\",\n  messages = list(\n    list(role = \"system\", content = \"You are a world economy expert.\"),\n    list(role = \"user\", content = prompt_text)\n  )\n)\n\n\nExplanation: - create_chat_completion() sends the prompt to the AI model. - The AI model returns a summary based on the provided data.\n\n\n3.2.5 Exercises\n1.  Web Scraping Practice:\n\nChoose a Wikipedia page with a table (e.g., list of countries by population).\nUse rvest to scrape the table into R.\nClean and format the data as needed.\n\nAPI Data Collection:\n\nIdentify a public API (e.g., OpenWeatherMap).\nUse R to access and retrieve data from the API.\nParse and analyze the data.\n\nAI Summarization:\n\nUse the data collected from the previous exercises.\nCreate prompts to summarize key insights using an AI model.\nCompare the AI-generated summaries with your own interpretations.\n\n\n\n3.2.6 References\n\nrvest Documentation: https://rvest.tidyverse.org/\nReal Python Requests Guide: https://realpython.com/python-requests/\nOpenAI API Documentation: https://platform.openai.com/docs",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Module 2: AI-Assisted Data Collection</span>"
    ]
  },
  {
    "objectID": "module2.html#overview",
    "href": "module2.html#overview",
    "title": "3  Module 2: AI-Assisted Data Collection",
    "section": "",
    "text": "Web Scraping: Extracting data from websites using tools like rvest in R.\nAPIs: Accessing structured data through Application Programming Interfaces.\nEthical Considerations: Understanding the legal and ethical implications of data collection.\nAI Summarization: Using AI models, such as GPT, to summarize and interpret collected data.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Module 2: AI-Assisted Data Collection</span>"
    ]
  },
  {
    "objectID": "module5.html#why-faculty-ai-literacy",
    "href": "module5.html#why-faculty-ai-literacy",
    "title": "6  Module 5: Faculty AI Literacy and Curriculum Redesign",
    "section": "",
    "text": "Just as students are learning to use AI, faculty need to “earn the right to use AI responsibly” by becoming AI literate themselves (Craig 2025). Our credibility in guiding students on AI use depends on our own understanding of its capabilities and pitfalls. In 2023-2024, there has been a flurry of efforts:\nNearly half of U.S. states have released some guidance on AI in education, and California even moved to include AI literacy in K-12 curriculum (Craig 2025). This signals a broad recognition that AI skills are becoming fundamental.\nUniversities (like those we discussed in Module 4) are offering faculty workshops, resource sites, and communities of practice around AI in teaching (University of Michigan-Dearborn Generative AI for Faculty).\nFaculty developers suggest treating AI not as an enemy but as a new tool – one that we should learn alongside our students. This ethos of continuous learning is key: technology will keep evolving, and so must we.\n\n\n6.1.1 Concrete steps to boost AI literacy among faculty include:\n\nTaking short courses or tutorials on AI basics. (For example, Google’s “Generative AI for Educators” – a free 2-hour course – or the University of Helsinki’s “Elements of AI” course are recommended resources (Craig 2025).\nExperimenting with AI in one’s own workflow: try using ChatGPT to draft an email, or use an AI image generator to create a figure for class. Hands-on experimentation demystifies the technology.\nReading case studies or research on AI in your discipline – e.g., how are political analysts using AI for polling or how are sociologists using it for text analysis? This can inspire ideas for your curriculum.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Module 5: Faculty AI Literacy and Curriculum Redesign</span>"
    ]
  },
  {
    "objectID": "module5.html#curriculum-redesign-for-the-ai-era",
    "href": "module5.html#curriculum-redesign-for-the-ai-era",
    "title": "6  Module 5: Faculty AI Literacy and Curriculum Redesign",
    "section": "6.2 2. Curriculum Redesign for the AI Era:",
    "text": "6.2 2. Curriculum Redesign for the AI Era:\n\n6.2.1 How should we adapt what (and how) we teach?\n\nIntegrating AI Topics: Consider adding a module on AI ethics or AI methods in relevant courses. For instance, a research methods class could have a week on “AI-assisted research,” where students try a tool like ChatGPT to generate hypotheses or survey questions and then discuss the quality of those outputs.\nEmbedding AI Assignments: In data science or statistics courses, include at least one assignment where students use an AI tool. For example, an assignment could be: “Use an AI coding assistant to help you write an analysis script, and then document how it helped and where you had to correct it.” This way, students learn with AI and also learn its limitations.\nAssessment and AI: Rethink assessments in light of AI. If take-home essays can be done with AI, perhaps shift to more in-class work or oral exams for certain learning outcomes. Or design assignments that require personal reflection or incorporation of class discussion (harder for AI to do well). Some instructors now ask students to submit “AI + me” portfolios – showing initial AI output and then how the student improved or corrected it, to assess learning.\nExample from Carnegie Mellon: A faculty member had students use ChatGPT to generate code for a task, then debug it themselves, turning AI into a learning partner rather than an illicit shortcut (Central Michigan University Generative AI Resources).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Module 5: Faculty AI Literacy and Curriculum Redesign</span>"
    ]
  },
  {
    "objectID": "module5.html#hands-on-exercise-5",
    "href": "module5.html#hands-on-exercise-5",
    "title": "6  Module 5: Faculty AI Literacy and Curriculum Redesign",
    "section": "6.3 3. Hands-On Exercise 5:",
    "text": "6.3 3. Hands-On Exercise 5:\n\n6.3.1 Curriculum Redesign Brainstorm.\n\nBreak into small groups on the following:\n\nPick a course you teach (or plan to teach) in the social sciences (e.g. Introduction to Quantative Methods or Descriptive and Inferential Statistics). Identify one aspect of the curriculum that could be updated to incorporate AI. It could be a single assignment, a new module, or a revision of how a topic is taught.\n\nWrite down your idea. For example: “In my Political Science Research Methods course, I will add a unit called ‘AI in Content Analysis’. Students will use an NLP AI service to code a set of tweets for sentiment, and we will compare the AI’s coding with human coding to discuss accuracy and bias.”\nConsider potential pitfalls: Will students have access to the tools? How will you evaluate their work fairly? How to ensure the use of AI actually enhances learning and isn’t just a gimmick?\nShare ideas and get feedback. Each group can present their favorite idea. We will compile these ideas into a shared document – this itself becomes a mini resource for all of us to take home.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Module 5: Faculty AI Literacy and Curriculum Redesign</span>"
    ]
  },
  {
    "objectID": "module5.html#ethical-and-future-considerations",
    "href": "module5.html#ethical-and-future-considerations",
    "title": "6  Module 5: Faculty AI Literacy and Curriculum Redesign",
    "section": "6.4 4. Ethical and Future Considerations:",
    "text": "6.4 4. Ethical and Future Considerations:\nAs we redesign curriculum, we must also instill ethical AI use in our students. They should graduate not only knowing how to use AI tools, but understanding issues of bias, privacy, and societal impact of AI. This might mean integrating discussions of AI ethics into courses (even technical ones). Moreover, faculty should stay updated: maybe designate an “AI ambassador” in your department who periodically shares new tools or developments with colleagues (since keeping up can feel overwhelming).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Module 5: Faculty AI Literacy and Curriculum Redesign</span>"
    ]
  },
  {
    "objectID": "module5.html#a-lighthearted-perspective",
    "href": "module5.html#a-lighthearted-perspective",
    "title": "6  Module 5: Faculty AI Literacy and Curriculum Redesign",
    "section": "6.5 5. A Lighthearted Perspective:",
    "text": "6.5 5. A Lighthearted Perspective:\nTeaching in the AI era can feel like chasing a moving target. One might joke, “By the time I update my syllabus, the AI will have updated itself twice!” Indeed, adaptability is the name of the game. But at its core, teaching has always been about guiding students through complexity – and AI is just the latest complexity. With collective effort and ongoing learning, we can turn AI from a threat to an asset in our teaching toolkit.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Module 5: Faculty AI Literacy and Curriculum Redesign</span>"
    ]
  },
  {
    "objectID": "module5.html#wrap-up",
    "href": "module5.html#wrap-up",
    "title": "6  Module 5: Faculty AI Literacy and Curriculum Redesign",
    "section": "6.6 6. Wrap-up:",
    "text": "6.6 6. Wrap-up:\nThis module caps our workshop by focusing on our growth as educators. Embracing AI in teaching doesn’t happen overnight – consider today a starting point. To continue the journey, tap into faculty communities (for example, the CSU AI Commons or EDUCAUSE initiatives on AI literacy alifornia State Univerity CfP) and keep experimenting. In the conclusion, we will summarize key takeaways from all modules and provide additional resources for your future exploration.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Module 5: Faculty AI Literacy and Curriculum Redesign</span>"
    ]
  }
]